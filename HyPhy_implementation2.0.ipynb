{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3269044407023279311\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12057230985513199349\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4318152065793836652\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15790676378\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7343260223171666058\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:1a:00.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow\n",
    "#using GPU, comment out if on CPU\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "# prerequisites\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scipy.stats import norm\n",
    "from tensorflow.keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.layers import concatenate as concat\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, concatenate,Reshape,Flatten\n",
    "from tensorflow.keras.layers import Reshape,UpSampling3D,RepeatVector,Conv3D,MaxPool3D\n",
    "import tensorflow.keras\n",
    "tensorflow.keras.backend.set_image_data_format('channels_first')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "#these are all chosen to make the overall distrubtion roughly unit gaussian... \n",
    "def density_transform(x):\n",
    "    return np.log10(3*x)\n",
    "\n",
    "def velocity_transform(x):\n",
    "    return x/75.0\n",
    "\n",
    "def temp_transform(x):\n",
    "    return (3.82-np.log10(x.clip(max=1000000))*3.8) +10\n",
    "\n",
    "\n",
    "def inv_density_transform(y):\n",
    "    return np.power(10,4*y)/3.0\n",
    "\n",
    "def inv_temp_transform(y):\n",
    "    prefac = ((4*y-13.8))/3.8\n",
    "    return np.power(10,prefac)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\n",
    "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_IDs_x,list_IDs_y, normy = True,\n",
    "                 to_fit=True, batch_size=32, \n",
    "                 n_channels=1, shuffle=True, inde = [0,1,2],\n",
    "                 max_num = 10, fix_direction=False):\n",
    "        \"\"\"Initialization\n",
    "        :param list_IDs: list of all 'label' ids to use in the generator\n",
    "        :param labels: list of image labels (file names)\n",
    "        :param image_path: path to images location\n",
    "        \n",
    "        :param to_fit: True to return X and y, False to return X only (I think always should be true?)\n",
    "        :param batch_size: batch size at each iteration\n",
    "        :param n_channels: number of image channels (should be 1)\n",
    "        :param shuffle: True to shuffle label indexes after every epoch\n",
    "        \"\"\"\n",
    "        self.list_IDs_x = list_IDs_x #filenames of density fields\n",
    "        self.list_IDs_y = list_IDs_y #filenames of hydro fields\n",
    "        self.max_num = max_num #maximum number of files to use per epoch\n",
    "        self.normy = normy #normalize hydrofield quantities (y/n)?\n",
    "        self.to_fit = to_fit #always True? False not implemented well...\n",
    "        self.batch_size = batch_size \n",
    "        self.n_channels = n_channels #should always be one\n",
    "        self.shuffle = shuffle #shuffle order of boxes\n",
    "        self.st = \"ijk\" #for using various reflection symmetries \n",
    "        self.max = self.__len__()\n",
    "        self.n = 0 #intializing get_item for random rearrangemnt\n",
    "        self.fix_direction = fix_direction #use mirror/reflection symmetries\n",
    "        self.perm = list(itertools.permutations(inde))\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        self.on_epoch_end()\n",
    "        return int(np.floor(len(self.list_IDs_x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        #choose random permulation\n",
    "        \n",
    "        #Choose orientation...\n",
    "        y = self.y[self.batch_size*index:self.batch_size*(index+1)]\n",
    "        X  = self.X[self.batch_size*index:self.batch_size*(index+1)]\n",
    "        if self.fix_direction:\n",
    "            ore = (0,1,2)\n",
    "        else:\n",
    "            ore = random.choice(self.perm)\n",
    "            #print(ore)\n",
    "     #   ore = (0, 1, 2)\n",
    "        #print(ore)\n",
    "        # Generate data\n",
    "        #X = self._perm_x(X,ore)\n",
    "        X = np.nan_to_num(X)\n",
    "        if self.to_fit:\n",
    "            #print(y.shape)\n",
    "            #y = self._perm_y(y,ore)\n",
    "            y = y\n",
    "            if self.normy:\n",
    "                y = np.nan_to_num(self._norm(y[:,[0,1,4],:,:]))\n",
    "            else:\n",
    "                y = np.nan_to_num(y[:,[0,1,4],:,:])\n",
    "            return [y,y*(1+np.random.randn(2,3,32,32,32)*0)],y #changed from 32,1,1,1,1\n",
    "\n",
    "\n",
    "    def _perm_x(self,hold,i):\n",
    "        #for mirror/reflection symmetries\n",
    "        Q = self.st[i[0]]+self.st[i[1]]+self.st[i[2]]\n",
    "       \n",
    "        t1_x_temp = np.einsum('mnijk->mn'+Q, hold)\n",
    "        t1_x_temp[:,[0,1, 2,3,4],:,:,:] = t1_x_temp[:,[0,i[0]+1,i[1]+1,i[2]+1,4],:,:,:]\n",
    "        return t1_x_temp\n",
    "    \n",
    "    def _perm_y(self,hold,i):\n",
    "        #for mirror/reflection symmetries\n",
    "\n",
    "        Q = self.st[i[0]]+self.st[i[1]]+self.st[i[2]]\n",
    "\n",
    "\n",
    "        t1_y_temp = np.einsum('mnijk->mn'+Q, hold)\n",
    "        t1_y_temp[:,[0,1, 2,3,4],:,:,:] = t1_y_temp[:,[0,i[0]+1,i[1]+1,i[2]+1,4],:,:,:]\n",
    "        return t1_y_temp\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(len(self.list_IDs_x))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "                # Generate indexes of the batch\n",
    "        print(self.indexes)\n",
    "        indexes = self.indexes[0:self.max_num]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_tempx = [self.list_IDs_x[k] for k in indexes]\n",
    "        list_IDs_tempy = [self.list_IDs_y[k] for k in indexes]\n",
    "        print(list_IDs_tempx)\n",
    "        self.X = self._generate_X(list_IDs_tempx)\n",
    "        self.y = self._generate_y(list_IDs_tempy)\n",
    "\n",
    "            \n",
    "    def _generate_X(self, list_IDs_temp_x):\n",
    "        \"\"\"Generates data containing batch_size images\n",
    "        :param list_IDs_temp: list of label ids to load\n",
    "        :return: batch of images\n",
    "        \"\"\"\n",
    "        # Initialization\n",
    "        test_x = []\n",
    "        for i in list_IDs_temp_x:\n",
    "            test_x.append([np.load(i)])\n",
    "       \n",
    "        test_x = np.reshape(np.array(test_x),(-1,8,32,32,32))[:,[0,1,4],:,:,:] #changed from 64^3, 5\n",
    "        return test_x\n",
    "\n",
    "    def _generate_y(self, list_IDs_temp_y):\n",
    "        \"\"\"Generates data containing batch_size masks\n",
    "        :param list_IDs_temp: list of label ids to load\n",
    "        :return: batch if masks\n",
    "        \"\"\"\n",
    "        test_y = []\n",
    "        for i in list_IDs_temp_y:\n",
    "            test_y.append([np.load(i)[:,:,:,:]])\n",
    "        test_y = np.reshape(np.array(test_y),(-1,8,32,32,32)) #changed from 64^3, 5\n",
    "                            \n",
    "        test_yn = test_y[:,:,:,:] #selecting only one baryon velocity\n",
    "        return test_yn\n",
    "#reducing variance so all variables have similar dynamic range: otherwise loss will be ->inf :'()'\n",
    "\n",
    "    def _norm(self,test_yn):\n",
    "        #if normed = True\n",
    "            \n",
    "            #test_yn[:,0] = ndimage.gaussian_filter(test_yn[:,0],0.0)\n",
    "            #test_yn[:,1] = ndimage.gaussian_filter(test_yn[:,1],0.0)\n",
    "            #test_yn[:,2] = ndimage.gaussian_filter(test_yn[:,2],0.0)\n",
    "            \n",
    "            \n",
    "            test_yn[:,0] = np.log10(test_yn[:,0].clip(min=0.00001,max=10000))#density_transform(test_yn[:,0].clip(min=0.00001))/4\n",
    "            test_yn[:,1] = test_yn[:,1]/100#velocity_transform(test_yn[:,1])/4\n",
    "            test_yn[:,2] = np.log10(test_yn[:,2].clip(min=0.00001,max=400000))#temp_transform(test_yn[:,2].clip(min=0.00001)).clip(max=3.0)/4\n",
    "            \n",
    "            \n",
    "            return test_yn\n",
    "        \n",
    "    def __next__(self):\n",
    "        if self.n >= self.max:\n",
    "            self.n = 0\n",
    "        result = self.__getitem__(self.n)\n",
    "        self.n += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv3D,Flatten,Conv3DTranspose,concatenate\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, concatenate,Reshape,Flatten\n",
    "from tensorflow.keras.layers import Reshape,UpSampling3D,RepeatVector,Conv3D,MaxPool3D, AvgPool3D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "import tensorflow.keras\n",
    "\n",
    "\n",
    "class HyPhy:\n",
    "    \n",
    "    \"\"\"\n",
    "    Class that holds the model for both train (cvae, and associated loss) and generation (gen),\n",
    "    \n",
    "    Currently takes as input just number of hidden dimensions and n_hidden, could \n",
    "    easily make more things free parameters to set...\n",
    "    \n",
    "    Set up slightly strangly to allow (hopefully) seamless switching between training and \n",
    "    generation, as well as changing generation size...\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=128,z_dim=27, edge_clip=10, rec_loss_factor = 1):\n",
    "        self.n_hidden = n_hidden #size of dense layers used to set mu, logvar for latent space\n",
    "        self.z_dim = z_dim #number of latent space dimensions\n",
    "        self.edge_clip = edge_clip #pixels to clip off of reconstructed tau for comparison\n",
    "        self.rec_loss_factor = rec_loss_factor #relative weight of kl loss vs. rec loss\n",
    "        self._init = 'lecun_normal'\n",
    "\n",
    "        self.__init_encoder__() #initialize encoder layers\n",
    "        self.__init_decoder__() #initialize decoder layers\n",
    "        \n",
    "        self.__init_cvae__() #creates training model\n",
    "        #self.__init_gen__() #just call HyPhy.gen(), not made by default\n",
    "    def __init_encoder__(self):\n",
    "        ## dm\n",
    "     \n",
    "        self.inter_up0 = Conv3D(4,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.inter_up0p = Conv3D(5,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_dm1 = Conv3D(6,2,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_dm1p = Conv3D(6,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "\n",
    "        self.encode_dm2 = Conv3D(8,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_dm3 = Conv3D(20,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_dm3p = Conv3D(30,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_dm4 = Conv3D(30,2,padding=\"same\",activation=\"selu\",kernel_initializer = self._init) ## linear?\n",
    "        self.encode_dm4p = Conv3D(30,2,padding=\"same\",activation=\"selu\",kernel_initializer = self._init) ## linear?\n",
    "\n",
    "        ## tau\n",
    "    \n",
    "        self.encode_tau1 = Conv3D(3,2,padding=\"same\") \n",
    "        self.encode_tau1P = Conv3D(4,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_tau2 = Conv3D(6,4,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_tau2P = Conv3D(8,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_tau3 = Conv3D(20,5,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_tau3P = Conv3D(30,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_tau4 = Conv3D(30,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.encode_tau4p = Conv3D(30,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "    def __init_decoder__(self):\n",
    "        \n",
    "        self.z_decoder2 = Conv3DTranspose(16,6,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)#Dense(n_hidden*3, activation='relu')\n",
    "        self.z_decoder2p = Conv3D(16,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.z_decoder3 = Conv3DTranspose(28,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.z_decoder3_mix = Conv3DTranspose(28,1,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.z_decoder3P = Conv3D(28,2,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)\n",
    "        self.z_decoder4 = Conv3DTranspose(24,1,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)#Dense(n_hidden*2, activation='linear')\n",
    "        self.z_decoder4P = Conv3D(24,2,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)#Dense(n_hidden*2, activation='linear')\n",
    "\n",
    "        self.y_decoder = Conv3D(24,1,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)#Dense(x_tr.shape[1], activation='linear')\n",
    "       # self.y_decoder_BN = BatchNormalization()\n",
    "        self.y_decoderP1 = Conv3D(8,5,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)#Dense(x_tr.shape[1], activation='linear')\n",
    "        self.y_decoderP2 = Conv3D(8,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)#Dense(x_tr.shape[1], activation='linear')\n",
    "        self.y_decoderP2_mix = Conv3D(8,2,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)#Dense(x_tr.shape[1], activation='linear')\n",
    "        self.y_decoderP3 = Conv3D(8,3,padding=\"same\",activation=\"tanh\")#Dense(x_tr.shape[1], activation='linear')\n",
    "        self.y_decoderP4 = Conv3D(3,3,padding=\"same\",activation=\"selu\",kernel_initializer = self._init)#Dense(x_tr.shape[1], activation='linear')\n",
    "    \n",
    "    def encoder_dm(self,dm_box):\n",
    "        \n",
    "        #getting dm field to same size as tau field...\n",
    "        dm0 = dm_box#UpSampling3D(name=\"dm_up1\")(dm_box)\n",
    "        dm0 = self.inter_up0(dm0)\n",
    "        dm0 = self.inter_up0p(dm0)\n",
    "        #dm0 = UpSampling3D(name=\"dm_up2\")(dm0)\n",
    "        \n",
    "        #step one\n",
    "        dm1 = self.encode_dm1(dm0)\n",
    "        dm1 = self.encode_dm1p(dm1)\n",
    "        dm1_p = MaxPool3D()(dm1)\n",
    "\n",
    "        #step two\n",
    "        dm2 = self.encode_dm2(dm1_p)\n",
    "        dm2_p = MaxPool3D()(dm2)\n",
    "      \n",
    "        #step three\n",
    "        dm3 = self.encode_dm3(dm2_p)\n",
    "        dm3 = self.encode_dm3p(dm3)\n",
    "\n",
    "        dm3_p = MaxPool3D()(dm3)\n",
    "\n",
    "        #step four\n",
    "        dm4 = self.encode_dm4(dm3_p)\n",
    "        dm4 = self.encode_dm4p(dm4)\n",
    "\n",
    "        dm4 = MaxPool3D()(dm4)\n",
    "        return dm0,dm1,dm2,dm3,dm4\n",
    "    \n",
    "    def encoder_tau(self,x_in,dm0,dm1,dm2,dm3,dm4):\n",
    "        \n",
    "        tau_box = Reshape((3,32,32,32))(x_in) #changed from 64^3 to 32^3\n",
    "\n",
    "        #step 1\n",
    "        tau1 = self.encode_tau1(tau_box)\n",
    "        tau1 = self.encode_tau1P(tau1)\n",
    "\n",
    "        #merge + step 2\n",
    "        tau1_dm1 = concatenate([dm1,tau1],axis=1)\n",
    "        tau2 = self.encode_tau2(tau1_dm1)\n",
    "        tau2 = self.encode_tau2P(tau2)\n",
    "        tau2_p = MaxPool3D()(tau2)\n",
    "\n",
    "        #merge + step 3\n",
    "\n",
    "        tau2_dm2 = concatenate([dm2,tau2_p],axis=1)\n",
    "        tau3 = self.encode_tau3(tau2_dm2)\n",
    "        tau3 = self.encode_tau3P(tau3)\n",
    "        tau3 = BatchNormalization()(tau3)\n",
    "        tau3_p = MaxPool3D()(tau3)\n",
    "\n",
    "        #merge + step 4\n",
    "        tau3_dm3 = concatenate([dm3,tau3_p],axis=1)\n",
    "        tau4 = self.encode_tau4(tau3_dm3)\n",
    "        tau4 = MaxPool3D()(tau4) #maybe do something else here? more layers?\n",
    "       # tau4 = self.encode_tau4p(tau4)\n",
    "        tau4 = MaxPool3D()(tau4)\n",
    "        return tau4\n",
    "        \n",
    "    def variational_block(self,tau4,dm4):\n",
    "        \n",
    "        x_encoded = concatenate([tau4,dm4])\n",
    "        x_encoded = Flatten()(x_encoded)\n",
    "        x_encoded = Dense(self.n_hidden, activation='selu',kernel_initializer = self._init)(x_encoded)\n",
    "        x_encoded = Dropout(.10)(x_encoded)\n",
    "        x_encoded = Dense(self.n_hidden//2, activation='selu',kernel_initializer = self._init)(x_encoded)\n",
    "        \n",
    "        self.mu = Dense(self.z_dim, activation='linear')(x_encoded)\n",
    "        self.log_var = Dense(self.z_dim, activation='linear')(x_encoded)\n",
    "        \n",
    "        def sampling(args):\n",
    "            mu, log_var = args\n",
    "            eps = K.random_normal(shape=(K.shape(dm4)[0], self.z_dim), mean=0., stddev=1.0)\n",
    "            return mu + K.exp(log_var/2.) * eps\n",
    "\n",
    "        z = Lambda(sampling, output_shape=(self.z_dim,))([self.mu, self.log_var])\n",
    "        return z\n",
    "    \n",
    "    def decoder(self,z_new, dm0,dm1,dm2,dm3,dm4):\n",
    "            \n",
    "        #dm4_new = Reshape((10,4,4,4))(dm4)\n",
    "\n",
    "        z_cond = concatenate([z_new, dm4],axis=1)\n",
    "    \n",
    "        z_decoded = self.z_decoder2(z_cond)\n",
    "        z_decoded = UpSampling3D()(z_decoded)\n",
    "        z_decoded = self.z_decoder2p(z_decoded)\n",
    "        z_decoded = UpSampling3D()(z_decoded)\n",
    "\n",
    "        z_decoded = concatenate([z_decoded,dm3],axis=1)\n",
    "        z_decoded = self.z_decoder3(z_decoded)\n",
    "        z_decoder = self.z_decoder3_mix(z_decoded)\n",
    "        z_decoded = self.z_decoder3P(z_decoded)\n",
    "        z_decoded = UpSampling3D()(z_decoded)\n",
    "\n",
    "        z_decoded = concatenate([z_decoded,dm2],axis=1)\n",
    "\n",
    "        z_decoded = self.z_decoder4(z_decoded)\n",
    "        z_decoded = self.z_decoder4P(z_decoded)\n",
    "\n",
    "        z_decoded = UpSampling3D()(z_decoded)\n",
    "\n",
    "        z_decoded = concatenate([z_decoded,dm1],axis=1)\n",
    "\n",
    "        y0 = self.y_decoder(z_decoded)\n",
    "       # y0 = self.y_decoder_BN(y0)\n",
    "        z_decoded = concatenate([y0,dm0],axis=1)\n",
    "        y0 = self.y_decoderP1(y0)\n",
    "        y0 = self.y_decoderP2(y0)\n",
    "        y0 = self.y_decoderP2_mix(y0)\n",
    "        y0 = self.y_decoderP3(y0)\n",
    "        y = self.y_decoderP4(y0)\n",
    "        return y\n",
    "    \n",
    "    def __init_cvae__(self):\n",
    "        \n",
    "        self.condition = Input(shape=(3,32,32,32),name=\"DM_field\") #changed from 64\n",
    "        #dm density, dm velocity, redshiftt\n",
    "        self.x_in = Input(shape=(3,32,32,32),name=\"tau_field\") #changed from 64\n",
    "        #baryon density, los velocity, temperature\n",
    "        dm_box = Reshape((3,32,32,32))(self.condition) #changed from 64\n",
    "\n",
    "        dm0,dm1,dm2,dm3,dm4 = self.encoder_dm(dm_box)\n",
    "        tau4 = self.encoder_tau(self.x_in,dm0,dm1,dm2,dm3,dm4)\n",
    "        \n",
    "        z = self.variational_block(tau4,dm4)\n",
    "        \n",
    "        z_new = Lambda(lambda x: tf.tensordot(x, K.ones((2,2,2)), axes=0))(z) #changed from 4,4,4\n",
    "        \n",
    "        y = self.decoder(z_new, dm0,dm1,dm2,dm3,dm4)\n",
    "        \n",
    "        self.cvae = Model([self.x_in, self.condition], y)\n",
    "    \n",
    "    def cvae_loss(self,x,y):\n",
    "        ec = int(self.edge_clip)\n",
    "        x_f = K.flatten(x[:,:,ec:-1*ec,ec:-1*ec,ec:-1*ec])\n",
    "        y_f = K.flatten(y[:,:,ec:-1*ec,ec:-1*ec,ec:-1*ec])\n",
    "\n",
    "        reconstruction_loss = losses.mean_squared_error(x_f, y_f)*16**3*4**3*self.rec_loss_factor\n",
    "        kl_loss = 0.5 * K.sum(K.square(self.mu) + K.exp(self.log_var) - self.log_var - 1, axis = -1)\n",
    "        loss = K.mean(reconstruction_loss + kl_loss)\n",
    "        return loss #changed from objectives\n",
    "    \n",
    "    def kl_loss(self,x,y):\n",
    "        # just for debugging\n",
    "        ec = int(self.edge_clip)\n",
    "        x_f = K.flatten(x[:,:,ec:-1*ec,ec:-1*ec,ec:-1*ec])\n",
    "        y_f = K.flatten(y[:,:,ec:-1*ec,ec:-1*ec,ec:-1*ec])\n",
    "        kl_loss = 0.5 * K.sum(K.square(self.mu) + K.exp(self.log_var) - self.log_var - 1, axis = -1)\n",
    "        return kl_loss\n",
    "    \n",
    "    def rec_loss(self,x,y):    \n",
    "    \n",
    "        ec = int(self.edge_clip)\n",
    "        x_f = K.flatten(x[:,:,ec:-1*ec,ec:-1*ec,ec:-1*ec])\n",
    "        y_f = K.flatten(y[:,:,ec:-1*ec,ec:-1*ec,ec:-1*ec])\n",
    "\n",
    "        reconstruction_loss = losses.mean_squared_error(x_f, y_f)*16**3*4**3*self.rec_loss_factor\n",
    "        return reconstruction_loss #changed from objectives\n",
    "    \n",
    "    def generator(self,size1 = 32,reduced_len=8):\n",
    "        \n",
    "        _condition = Input(shape=(3,size1,size1,size1),name=\"DM_field\")\n",
    "        _z = Input(shape=(self.z_dim,))\n",
    "        #x_in = Input(shape=(3,64,64,64),name=\"tau_field\")\n",
    "        \n",
    "        dm0,dm1,dm2,dm3,dm4 = self.encoder_dm(_condition)\n",
    "        \n",
    "        _z_new = Lambda(lambda x: tf.tensordot(x, K.ones((reduced_len,reduced_len,reduced_len)), axes=0))(_z)\n",
    "        \n",
    "        _y = self.decoder(_z_new, dm0,dm1,dm2,dm3,dm4)\n",
    "        \n",
    "        self.gen = Model([_condition,_z], _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "listEul = sorted(glob.glob(\"/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_*\")) \n",
    "listLag = sorted(glob.glob(\"/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Lag/dens_*\"))\n",
    "listReion = sorted(glob.glob(\"/global/cscratch1/sd/tmedan/notebooks/HyPhy_reionization/reion_*\")) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 2 4 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      "[0 3 2 1 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n"
     ]
    }
   ],
   "source": [
    "q_tr = DataGenerator(listEul[:5],listReion[:5],normy=True,max_num=2,batch_size=2,fix_direction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/common/software/tensorflow/gpu-tensorflow/1.15.0-py37/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/common/software/tensorflow/gpu-tensorflow/1.15.0-py37/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:4277: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Hy = HyPhy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "DM_field (InputLayer)           [(None, 3, 32, 32, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 3, 32, 32, 32 0           DM_field[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 4, 32, 32, 32 328         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tau_field (InputLayer)          [(None, 3, 32, 32, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 5, 32, 32, 32 545         conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 3, 32, 32, 32 0           tau_field[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 6, 32, 32, 32 246         conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 3, 32, 32, 32 75          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 6, 32, 32, 32 978         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 4, 32, 32, 32 328         conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 10, 32, 32, 3 0           conv3d_3[0][0]                   \n",
      "                                                                 conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 6, 32, 32, 32 3846        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 6, 16, 16, 16 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 8, 32, 32, 32 1304        conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 8, 16, 16, 16 1304        max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 8, 16, 16, 16 0           conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 16, 1 0           conv3d_4[0][0]                   \n",
      "                                                                 max_pooling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 20, 16, 16, 1 40020       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 8, 8, 8, 8)   0           conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 30, 16, 16, 1 16230       conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 20, 8, 8, 8)  4340        max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 30, 16, 16, 1 64          conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 30, 8, 8, 8)  16230       conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3D)  (None, 30, 8, 8, 8)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 60, 8, 8, 8)  0           conv3d_6[0][0]                   \n",
      "                                                                 max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 30, 4, 4, 4)  0           conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 30, 8, 8, 8)  48630       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 30, 4, 4, 4)  7230        max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3D)  (None, 30, 4, 4, 4)  0           conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 30, 4, 4, 4)  7230        conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3D)  (None, 30, 2, 2, 2)  0           max_pooling3d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 30, 2, 2, 2)  0           conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 30, 2, 2, 4)  0           max_pooling3d_7[0][0]            \n",
      "                                                                 max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 480)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          61568       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 27)           1755        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 27)           1755        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 27)           0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 27, 2, 2, 2)  8           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 57, 2, 2, 2)  0           lambda_1[0][0]                   \n",
      "                                                                 max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose (Conv3DTranspo (None, 16, 2, 2, 2)  197008      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d (UpSampling3D)    (None, 16, 4, 4, 4)  0           conv3d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 16, 4, 4, 4)  6928        up_sampling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 16, 8, 8, 8)  0           conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 46, 8, 8, 8)  0           up_sampling3d_1[0][0]            \n",
      "                                                                 conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTrans (None, 28, 8, 8, 8)  34804       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 28, 8, 8, 8)  6300        conv3d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 28, 16, 16, 1 0           conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 36, 16, 16, 1 0           up_sampling3d_2[0][0]            \n",
      "                                                                 conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTrans (None, 24, 16, 16, 1 888         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 24, 16, 16, 1 4632        conv3d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 24, 32, 32, 3 0           conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 30, 32, 32, 3 0           up_sampling3d_3[0][0]            \n",
      "                                                                 conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 24, 32, 32, 3 744         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 8, 32, 32, 32 24008       conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 8, 32, 32, 32 1736        conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 8, 32, 32, 32 520         conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)              (None, 8, 32, 32, 32 1736        conv3d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)              (None, 3, 32, 32, 32 651         conv3d_24[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 502,225\n",
      "Trainable params: 502,193\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Hy.cvae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changed in rec_loss and cvae_loss the mean_squared_error from 'objectives'\n",
    "#to tensorflow.compat.v1.metrics.mean_squared_error in an attempy to make \n",
    "#the loss functions work, however, failed to get tf.keras.objectives\n",
    "#to import into my notebook\n",
    "#Therefore tried basic mean squared error here, was able to \n",
    "#run this cell and get training to begin\n",
    "adam = optimizers.Adam(clipnorm=0.9,lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "Hy.cvae.compile(optimizer=adam,loss= 'mse') #Hy.cvae_loss, metrics = [Hy.kl_loss, Hy.rec_loss])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "[1 0 3 4 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      " 1/30 [>.............................] - ETA: 7:48 - loss: 1.6746[2 0 1 4 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      " 3/30 [==>...........................] - ETA: 3:54 - loss: 1.2029[4 3 2 1 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      " 6/30 [=====>........................] - ETA: 2:19 - loss: 0.8227[0 4 1 2 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      " 7/30 [======>.......................] - ETA: 2:19 - loss: 0.7387[2 1 0 3 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      " 9/30 [========>.....................] - ETA: 1:58 - loss: 0.6199[4 1 0 2 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "11/30 [==========>...................] - ETA: 1:41 - loss: 0.5418[4 1 2 0 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "13/30 [============>.................] - ETA: 1:27 - loss: 0.4884[2 1 0 4 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "15/30 [==============>...............] - ETA: 1:14 - loss: 0.4423[2 1 4 3 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "17/30 [================>.............] - ETA: 1:03 - loss: 0.4070[2 1 4 3 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "19/30 [==================>...........] - ETA: 52s - loss: 0.3770 [0 4 2 1 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "21/30 [====================>.........] - ETA: 42s - loss: 0.3538[4 1 3 0 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "23/30 [======================>.......] - ETA: 32s - loss: 0.3347[2 0 4 1 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      "25/30 [========================>.....] - ETA: 22s - loss: 0.3175[4 2 3 1 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      "27/30 [==========================>...] - ETA: 13s - loss: 0.3021[4 2 1 3 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      "29/30 [============================>.] - ETA: 4s - loss: 0.2898[1 2 4 0 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      "30/30 [==============================] - 130s 4s/step - loss: 0.2841\n",
      "Epoch 2/5\n",
      " 1/30 [>.............................] - ETA: 4:02 - loss: 0.1231[3 2 1 0 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      " 3/30 [==>...........................] - ETA: 2:25 - loss: 0.1198[1 3 2 0 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      " 5/30 [====>.........................] - ETA: 1:59 - loss: 0.1141[0 1 3 2 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      " 7/30 [======>.......................] - ETA: 1:44 - loss: 0.1112[0 1 2 3 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      " 9/30 [========>.....................] - ETA: 1:33 - loss: 0.1098[2 0 3 1 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      "11/30 [==========>...................] - ETA: 1:22 - loss: 0.1115[3 4 1 2 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "13/30 [============>.................] - ETA: 1:12 - loss: 0.1091[2 1 4 3 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "15/30 [==============>...............] - ETA: 1:04 - loss: 0.1053[2 3 4 1 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      "17/30 [================>.............] - ETA: 54s - loss: 0.1038 [4 1 3 0 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "19/30 [==================>...........] - ETA: 46s - loss: 0.1032[2 4 0 1 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "21/30 [====================>.........] - ETA: 37s - loss: 0.1022[0 2 4 1 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      "23/30 [======================>.......] - ETA: 28s - loss: 0.1015[2 1 0 4 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "25/30 [========================>.....] - ETA: 20s - loss: 0.1006[0 3 1 4 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      "27/30 [==========================>...] - ETA: 12s - loss: 0.0994[2 0 1 3 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      "29/30 [============================>.] - ETA: 4s - loss: 0.0984 [3 2 0 1 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      "30/30 [==============================] - 118s 4s/step - loss: 0.0974\n",
      "Epoch 3/5\n",
      " 1/30 [>.............................] - ETA: 3:41 - loss: 0.0816[3 0 2 1 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      " 3/30 [==>...........................] - ETA: 2:17 - loss: 0.0806[4 2 0 3 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      " 5/30 [====>.........................] - ETA: 1:56 - loss: 0.0874[4 0 2 3 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      " 7/30 [======>.......................] - ETA: 1:41 - loss: 0.0953[1 0 2 3 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      " 9/30 [========>.....................] - ETA: 1:31 - loss: 0.0974[0 4 2 1 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "11/30 [==========>...................] - ETA: 1:20 - loss: 0.0959[3 0 2 1 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      "13/30 [============>.................] - ETA: 1:11 - loss: 0.0930[0 2 1 4 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      "15/30 [==============>...............] - ETA: 1:02 - loss: 0.0905[1 4 0 2 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "17/30 [================>.............] - ETA: 53s - loss: 0.0895[3 2 0 4 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      "19/30 [==================>...........] - ETA: 45s - loss: 0.0882[0 2 4 1 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      "21/30 [====================>.........] - ETA: 36s - loss: 0.0871[3 1 0 4 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "23/30 [======================>.......] - ETA: 28s - loss: 0.0851[3 4 0 1 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "25/30 [========================>.....] - ETA: 20s - loss: 0.0842[3 4 1 0 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "27/30 [==========================>...] - ETA: 12s - loss: 0.0826[2 3 0 4 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      "29/30 [============================>.] - ETA: 4s - loss: 0.0818[0 3 1 4 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      "30/30 [==============================] - 118s 4s/step - loss: 0.0813\n",
      "Epoch 4/5\n",
      " 1/30 [>.............................] - ETA: 3:35 - loss: 0.0631[4 0 3 1 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      " 3/30 [==>...........................] - ETA: 2:17 - loss: 0.0742[4 3 1 2 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      " 5/30 [====>.........................] - ETA: 1:57 - loss: 0.0800[2 1 0 4 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      " 7/30 [======>.......................] - ETA: 1:43 - loss: 0.0794[3 2 0 4 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      " 9/30 [========>.....................] - ETA: 1:31 - loss: 0.0770[0 4 2 1 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "11/30 [==========>...................] - ETA: 1:21 - loss: 0.0746[3 4 1 2 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "13/30 [============>.................] - ETA: 1:11 - loss: 0.0726[2 0 1 4 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      "15/30 [==============>...............] - ETA: 1:02 - loss: 0.0719[4 1 0 3 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "17/30 [================>.............] - ETA: 53s - loss: 0.0729[2 4 3 1 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "19/30 [==================>...........] - ETA: 45s - loss: 0.0727[0 3 4 2 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      "21/30 [====================>.........] - ETA: 36s - loss: 0.0715[3 2 4 0 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      "23/30 [======================>.......] - ETA: 28s - loss: 0.0713[3 2 1 4 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      "25/30 [========================>.....] - ETA: 20s - loss: 0.0702[2 0 3 4 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      "27/30 [==========================>...] - ETA: 12s - loss: 0.0698[2 1 0 3 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "29/30 [============================>.] - ETA: 4s - loss: 0.0693[1 4 0 2 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "30/30 [==============================] - 117s 4s/step - loss: 0.0688\n",
      "Epoch 5/5\n",
      " 1/30 [>.............................] - ETA: 3:49 - loss: 0.0835[3 2 4 1 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      " 3/30 [==>...........................] - ETA: 2:22 - loss: 0.0766[2 3 0 1 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      " 5/30 [====>.........................] - ETA: 1:57 - loss: 0.0680[3 2 4 1 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy']\n",
      " 7/30 [======>.......................] - ETA: 1:43 - loss: 0.0632[2 0 1 4 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      " 9/30 [========>.....................] - ETA: 1:31 - loss: 0.0625[0 1 2 4 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "11/30 [==========>...................] - ETA: 1:21 - loss: 0.0598[2 4 0 1 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_2.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "13/30 [============>.................] - ETA: 1:12 - loss: 0.0597[1 0 4 2 3]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      "15/30 [==============>...............] - ETA: 1:03 - loss: 0.0602[0 3 2 4 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      "17/30 [================>.............] - ETA: 54s - loss: 0.0612[3 1 0 4 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy']\n",
      "19/30 [==================>...........] - ETA: 45s - loss: 0.0599[1 3 4 2 0]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      "21/30 [====================>.........] - ETA: 37s - loss: 0.0609[3 4 2 0 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy']\n",
      "23/30 [======================>.......] - ETA: 28s - loss: 0.0611[3 0 2 4 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      "25/30 [========================>.....] - ETA: 20s - loss: 0.0611[1 0 3 2 4]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_1.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      "27/30 [==========================>...] - ETA: 12s - loss: 0.0612[4 3 1 0 2]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_3.npy']\n",
      "29/30 [============================>.] - ETA: 4s - loss: 0.0622 [4 0 2 3 1]\n",
      "['/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_4.npy', '/global/cscratch1/sd/tmedan/notebooks/HyPhy_density_Eul/dens_0.npy']\n",
      "30/30 [==============================] - 118s 4s/step - loss: 0.0627\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for i in range(0,50):\n",
    "#     print(i)\n",
    "hi = Hy.cvae.fit_generator(generator=q_tr,\n",
    "         shuffle=True,\n",
    "            verbose=1,\n",
    "            steps_per_epoch=30,\n",
    "            epochs=5) \n",
    "         #callbacks=[logger,checkpoint,LambdaCallback(on_epoch_end=q_tr.on_epoch_end())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells below are for displaying my preprocessing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing of HyPhy_ density files\n",
    "\n",
    "#Below are two functions used in the pre-processing of my density fields BEFORE\n",
    "#they are saved to .npy files\n",
    "\n",
    "def scale_field(field_in, field_type, inv=False):\n",
    "    '''\n",
    "    function to scale Lagrangian, Eulerian, and reionization fields\n",
    "    from their physical units to the range (0,1), and invert this scaling if needed.\n",
    "    Can choose other scalings from e.g. https://en.wikipedia.org/wiki/Feature_scaling - right now does min-max scaling.\n",
    "    Keyword arguments:\n",
    "    field_in -- the field to scale\n",
    "    field_type -- type of field: 'lag', 'eul', or 'reion'\n",
    "    inv -- False=forward scaling from physical units to normalized, True=inverse\n",
    "    \"\"\"\n",
    "    '''\n",
    "    field_types =  ['eul', 'lag', 'reion']\n",
    "    field_mins  = np.array([ -1.        , -23.45174217,   6.69999981])\n",
    "    field_maxs  = np.array([11.14400196, 22.52767944, 16.        ])\n",
    "    ind = field_types.index(field_type)\n",
    "    fmin = field_mins[ind]\n",
    "    fmax = field_maxs[ind]\n",
    "    #min max scaling\n",
    "    if not inv:\n",
    "        return (field_in - fmin)/(fmax - fmin)\n",
    "    if inv:\n",
    "        return field_in * (fmax - fmin) + fmin\n",
    "    \n",
    "def cubify(arr, newshape):\n",
    "    '''stolen from https://stackoverflow.com/questions/42297115/numpy-split-cube-into-cubes'''\n",
    "    oldshape = np.array(arr.shape)\n",
    "    repeats = (oldshape / newshape).astype(int)\n",
    "    tmpshape = np.column_stack([repeats, newshape]).ravel()\n",
    "    order = np.arange(len(tmpshape))\n",
    "    order = np.concatenate([order[::2], order[1::2]])\n",
    "    \n",
    "    # newshape must divide oldshape evenly or else ValueError will be raised\n",
    "    return arr.reshape(tmpshape).transpose(order).reshape(-1, *newshape)\n",
    "\n",
    "def uncubify(arr, oldshape):\n",
    "    '''stolen from https://stackoverflow.com/questions/42297115/numpy-split-cube-into-cubes'''\n",
    "    N, newshape = arr.shape[0], arr.shape[1:]\n",
    "    oldshape = np.array(oldshape)    \n",
    "    repeats = (oldshape / newshape).astype(int)\n",
    "    tmpshape = np.concatenate([repeats, newshape])\n",
    "    order = np.arange(len(tmpshape)).reshape(2, -1).ravel(order='F')\n",
    "    return arr.reshape(tmpshape).transpose(order).reshape(oldshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "#Here we have the data processing I used on my density files to turn it \n",
    "#into files of size (n_files,4096,32,32,32)\n",
    "\n",
    "#NO NEED TO RUN THIS AGAIN\n",
    "datadir = '/global/cscratch1/sd/tmedan/notebooks/'\n",
    "def data_feeder(n_files, img_shape):\n",
    "    sim_size  =  512\n",
    "    n_subcube = int((sim_size//img_shape)**3)\n",
    "    # make empty array first.\n",
    "    densE = np.zeros((n_files, n_subcube, img_shape, img_shape, img_shape))\n",
    "    densL = np.zeros((n_files, n_subcube, img_shape, img_shape, img_shape))\n",
    "    reion = np.zeros((n_files, n_subcube, img_shape, img_shape, img_shape))\n",
    "    for i in range(n_files):\n",
    "        # load in simulation\n",
    "        densEfile_i = datadir+'density_Eul/dens_{:02d}'.format(i)\n",
    "        densE_i = np.fromfile(open(densEfile_i),count=sim_size**3,dtype=np.float32).reshape(sim_size, sim_size, sim_size)\n",
    "        \n",
    "        densLfile_i = datadir+'density_Lag/dens_{:02d}'.format(i)\n",
    "        densL_i = np.fromfile(open(densLfile_i),count=sim_size**3,dtype=np.float32).reshape(sim_size, sim_size, sim_size)\n",
    "        \n",
    "        reionfile_i = datadir+'reionization/reion_{:02d}'.format(i)\n",
    "        reion_i = np.fromfile(open(reionfile_i),count=sim_size**3,dtype=np.float32).reshape(sim_size, sim_size, sim_size)\n",
    "        #reshape to subcubes\n",
    "        densE[i] = cubify(densE_i,(img_shape,img_shape,img_shape))\n",
    "        densL[i] = cubify(densL_i,(img_shape,img_shape,img_shape))\n",
    "        reion[i] = cubify(reion_i,(img_shape,img_shape,img_shape))\n",
    "    # add additional axis for number of channels\n",
    "#     densE = densE[..., np.newaxis]\n",
    "#     densL = densL[..., np.newaxis]\n",
    "#     reion = reion[..., np.newaxis]       #these were taken out to fit hyphy data\n",
    "    # scale all fields at once\n",
    "    densE_scaled = scale_field(densE,'eul')\n",
    "    densL_scaled = scale_field(densL,'lag')\n",
    "    reion_scaled = scale_field(reion,'reion')\n",
    "    return densE_scaled,densL_scaled,reion_scaled\n",
    "\n",
    "data = data_feeder(5,32)\n",
    "densE_train = data[0]\n",
    "densL_train = data[1]\n",
    "reion_train = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary to .npy files for use in HyPhy\n",
    "datadir = '/global/cscratch1/sd/tmedan/notebooks/'\n",
    "\n",
    "# Use process like this load to save binary float32 files as .npy into new directory\n",
    "# for HyPhy usage\n",
    "\n",
    "#saves each files from the list of n_files from above as it's own volume in the \n",
    "#correct data format\n",
    "for i in range(5):\n",
    "        # load in simulation\n",
    "        \n",
    "        #arr_eul = np.fromfile(densE_train[i],dtype=np.float32)\n",
    "        np.save('HyPhy_density_Eul/dens_'+str(i)+'.npy',densE_train[i])\n",
    "        \n",
    "        \n",
    "        #arr_lag = np.fromfile(densL_train[i],dtype=np.float32)\n",
    "        np.save('HyPhy_density_Lag/dens_'+str(i)+'.npy',densL_train[i])\n",
    "        \n",
    "        \n",
    "        #arr_reion = np.fromfile(reion_train[i],dtype=np.float32)\n",
    "        np.save('HyPhy_reionization/reion_'+str(i)+'.npy',reion_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each filed of data then becomes of the shape\n",
    "(4096, 32, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-v1.15.0-gpu",
   "language": "python",
   "name": "tensorflow_gpu_1.15.0_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
