{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 512\n",
    "datadir = '/global/cscratch1/sd/tmedan/notebooks/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ScaleField(): \n",
    "    # used min-max scaling HERE ONLY \n",
    "    def __init__(self, field):\n",
    "        super(ScaleField, self).__init__()\n",
    "\n",
    "        self.fmin  = field.min()\n",
    "        self.fmax  = field.max() \n",
    "        self.fmean = field.mean()\n",
    "    \n",
    "    def scale(self, field, inv=False): \n",
    "        if not inv:\n",
    "            self.scaled = True\n",
    "            return (field - self.fmin) / (self.fmax - self.fmin)\n",
    "        if inv:\n",
    "            self.scaled = False\n",
    "            return field * (self.fmax - self.fmin) + self.fmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = 32\n",
    "def cubify(arr, newshape):\n",
    "    '''stolen from https://stackoverflow.com/questions/42297115/numpy-split-cube-into-cubes'''\n",
    "    oldshape = np.array(arr.shape)\n",
    "    repeats = (oldshape / newshape).astype(int)\n",
    "    tmpshape = np.column_stack([repeats, newshape]).ravel()\n",
    "    order = np.arange(len(tmpshape))\n",
    "    order = np.concatenate([order[::2], order[1::2]])\n",
    "    \n",
    "    # newshape must divide oldshape evenly or else ValueError will be raised\n",
    "    return arr.reshape(tmpshape).transpose(order).reshape(-1, *newshape)\n",
    "\n",
    "def uncubify(arr, oldshape):\n",
    "    '''stolen from https://stackoverflow.com/questions/42297115/numpy-split-cube-into-cubes'''\n",
    "    N, newshape = arr.shape[0], arr.shape[1:]\n",
    "    oldshape = np.array(oldshape)    \n",
    "    repeats = (oldshape / newshape).astype(int)\n",
    "    tmpshape = np.concatenate([repeats, newshape])\n",
    "    order = np.arange(len(tmpshape)).reshape(2, -1).ravel(order='F')\n",
    "    return arr.reshape(tmpshape).transpose(order).reshape(oldshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_conv(n_filters):\n",
    "    return tfk.Sequential([\n",
    "        tfkl.Conv3D(n_filters, kernel_size = (4,4,4) , strides=(2,2,2),\n",
    "                    padding='same'),\n",
    "        tfkl.LeakyReLU()])  \n",
    "\n",
    "def up_conv(n_filters):\n",
    "    return tfk.Sequential([\n",
    "        tfkl.Conv3DTranspose(n_filters, kernel_size = (4,4,4), strides = (2,2,2), \n",
    "                         padding='same'),\n",
    "        tfkl.ReLU()])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UNet(tfk.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UNet,self).__init__()\n",
    "        self.conv_down1 = down_conv(4)\n",
    "        self.conv_down2 = down_conv(8)\n",
    "        self.conv_down3 = down_conv(16)\n",
    "        \n",
    "        self.conv_up3 = up_conv(32)\n",
    "        self.conv_up2 = up_conv(64)\n",
    "        self.conv_last = tfkl.Conv3DTranspose(64, kernel_size=(4,4,4), strides=(2,2,2), \n",
    "                                              padding='same')\n",
    "        \n",
    "        \n",
    "    def call(self,input):\n",
    "        conv1 = self.conv_down1(input) \n",
    "        conv2 = self.conv_down2(conv1)\n",
    "        conv3 = self.conv_down3(conv2) \n",
    " \n",
    "        \n",
    "    \n",
    "        x = self.conv_up3(conv3) \n",
    "        x = self.conv_up2(x)\n",
    "        x = self.conv_last(x)\n",
    "        out = tfkl.Activation('relu')(x)\n",
    "        return out\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"u_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      multiple                  260       \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    multiple                  2056      \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    multiple                  8208      \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    multiple                  32800     \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    multiple                  131136    \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTr multiple                  262208    \n",
      "=================================================================\n",
      "Total params: 436,668\n",
      "Trainable params: 436,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=(None, img_shape,img_shape,img_shape, 1))\n",
    "optimizer = tfk.optimizers.Adam(1e-3)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "\n",
    "def data_feeder(n_files, img_shape):\n",
    "    sim_size  =  512\n",
    "    n_subcube = int((sim_size//img_shape)**3)\n",
    "    # make empty array first.\n",
    "    densE = np.zeros((n_files, n_subcube, img_shape, img_shape, img_shape))\n",
    "    densL = np.zeros((n_files, n_subcube, img_shape, img_shape, img_shape))\n",
    "    reion = np.zeros((n_files, n_subcube, img_shape, img_shape, img_shape))\n",
    "    for i in range(n_files):\n",
    "        # load in simulation\n",
    "        densEfile_i = datadir+'density_Eul/dens_{:02d}'.format(i)\n",
    "        densE_i = np.fromfile(open(densEfile_i),count=sim_size**3,dtype=np.float32).reshape(sim_size, sim_size, sim_size)\n",
    "        \n",
    "        densLfile_i = datadir+'density_Lag/dens_{:02d}'.format(i)\n",
    "        densL_i = np.fromfile(open(densLfile_i),count=sim_size**3,dtype=np.float32).reshape(sim_size, sim_size, sim_size)\n",
    "        \n",
    "        reionfile_i = datadir+'reionization/reion_{:02d}'.format(i)\n",
    "        reion_i = np.fromfile(open(reionfile_i),count=sim_size**3,dtype=np.float32).reshape(sim_size, sim_size, sim_size)\n",
    "        #reshape to subcubes\n",
    "        densE[i] = cubify(densE_i,(img_shape,img_shape,img_shape))\n",
    "        densL[i] = cubify(densL_i,(img_shape,img_shape,img_shape))\n",
    "        reion[i] = cubify(reion_i,(img_shape,img_shape,img_shape))\n",
    "    # add additional axis for number of channels\n",
    "    densE = densE[..., np.newaxis]\n",
    "    densL = densL[..., np.newaxis]\n",
    "    reion = reion[..., np.newaxis]\n",
    "    # scale all fields at once\n",
    "    densE = ScaleField(densE).scale(field=densE)\n",
    "    densL = ScaleField(densL).scale(field=densL)\n",
    "    reion = ScaleField(reion).scale(field=reion)\n",
    "    return densE,densL,reion\n",
    "\n",
    "data = data_feeder(1,32)\n",
    "densE_train = data[0]\n",
    "densL_train = data[1]\n",
    "reion_train = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 32, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# get test data\n",
    "\n",
    "freion = open(datadir+'reionization/reion_05')\n",
    "fdens  = open(datadir+'density_Eul/dens_05')\n",
    "\n",
    "x_test  = np.fromfile(fdens, count=N**3, dtype=np.float32).reshape(N,N,N)\n",
    "y_test  = np.fromfile(freion, count=N**3, dtype=np.float32).reshape(N,N,N)\n",
    "\n",
    "\n",
    "x_test = ScaleField(x_test).scale(field=x_test)\n",
    "y_test = ScaleField(y_test).scale(field=y_test)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(x_test[0])\n",
    "# plt.colorbar()\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(y_test[0])\n",
    "# plt.colorbar()\n",
    "\n",
    "x_test = cubify(x_test,  (img_shape, img_shape, img_shape))[..., np.newaxis]\n",
    "y_test = cubify(y_test,  (img_shape, img_shape, img_shape))[..., np.newaxis]\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "reion_test  = ScaleField(y_test).scale(field=y_test,inv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "116/116 [==============================] - 15s 131ms/step - loss: 0.0165 - mae: 0.0859 - val_loss: 0.0111 - val_mae: 0.0711\n",
      "Epoch 2/2\n",
      "116/116 [==============================] - 14s 124ms/step - loss: 0.0083 - mae: 0.0546 - val_loss: 0.0075 - val_mae: 0.0493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'submit for one hour\\nuse cori gpu submission \\nthrough srun\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(densE_train.shape[0]):\n",
    "    history = model.fit(densE_train[i],reion_train[i],\n",
    "                    epochs=2,\n",
    "                    validation_split=0.1)\n",
    "    \n",
    "'''submit for one hour\n",
    "use cori gpu submission \n",
    "through srun\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.savefig('true_v-net')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: Resnet50/assets\n"
     ]
    }
   ],
   "source": [
    "#model.save('true_v-net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[52,64,16,16,16] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node u_net/conv3d_transpose_2/conv3d_transpose (defined at <ipython-input-6-98fdb9032d32>:62) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_3054]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node u_net/conv3d_transpose_2/conv3d_transpose:\n u_net/sequential_4/re_lu_1/Relu (defined at <ipython-input-6-98fdb9032d32>:61)\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4a7f4be39bdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m52\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreion_test_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScaleField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[52,64,16,16,16] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node u_net/conv3d_transpose_2/conv3d_transpose (defined at <ipython-input-6-98fdb9032d32>:62) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_3054]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node u_net/conv3d_transpose_2/conv3d_transpose:\n u_net/sequential_4/re_lu_1/Relu (defined at <ipython-input-6-98fdb9032d32>:61)\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "y_test_predict = model.predict(x_test,batch_size=52)\n",
    "\n",
    "reion_test_predict = ScaleField(y_test_predict).scale(field = y_test_predict, inv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yshow_predict = reion_test_predict[0,img_shape//2, ..., 0]\n",
    "yshow = reion_test[0,img_shape//2, ..., 0]\n",
    "xshow = x_test[0,img_shape//2, ..., 0]\n",
    "\n",
    "ymin = yshow.min()\n",
    "ymax = yshow.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(yshow.flatten(),yshow_predict.flatten(),c='k',s=0.5)\n",
    "xx = np.linspace(yshow.min(), yshow.max(), 100)\n",
    "plt.plot(xx,xx, 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(yshow_predict, vmin = ymin, vmax=ymax)\n",
    "plt.colorbar()\n",
    "plt.title('V-Net Prediction')\n",
    "plt.savefig('V-Net_predict')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(yshow, vmin = ymin, vmax=ymax)\n",
    "plt.colorbar()\n",
    "plt.title('Actual 21CM Run')\n",
    "plt.savefig('V-Net_actual')\n",
    "\n",
    "diff = yshow_predict-yshow\n",
    "plt.figure()\n",
    "plt.imshow(diff, vmin=-np.abs(diff).max(), vmax=np.abs(diff).max(), cmap=plt.get_cmap('coolwarm'))\n",
    "plt.colorbar()\n",
    "plt.title('V-Net Difference')\n",
    "plt.savefig('V-Net_diff')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-v2.2.0-gpu",
   "language": "python",
   "name": "tensorflow_gpu_2.2.0-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
